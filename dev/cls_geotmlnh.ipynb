{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os; import numpy\n",
    "from gasp3.sql.fm import Q_to_df\n",
    "from gasp3.adv.txtcls.cls import text_prediction\n",
    "from gasp3.adv.txtcls.eval import binary_eval\n",
    "from gasp3.adv.txtcls.freq import correlated_words\n",
    "from gasp3.pyt.df.stats import df_to_freqdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "conDB = {\n",
    "    'HOST' : 'localhost', 'PORT' : '5432', 'USER' : 'postgres',\n",
    "    'PASSWORD' : 'admin', 'DATABASE' : 'expvgim_db'\n",
    "}\n",
    "\n",
    "TBL_SCHEMA = {\n",
    "    'SAMPLE_T' : 'geotmlnh_facesample',\n",
    "    'SAMPLE_FK' : 'postid',\n",
    "    'DATA_T'   : 'geotmlnh_facedata',\n",
    "    'DATA_ID'  : 'post_id',\n",
    "    'TXT_COL'  : (\n",
    "        \"CASE WHEN geotmlnh_facedata.type = 'link' \"\n",
    "        \"THEN lower(unaccent(geotmlnh_facedata.description)) \"\n",
    "        \"ELSE lower(unaccent(geotmlnh_facedata.message)) END\"\n",
    "    ),\n",
    "    'TIME_COL' : 'datahora',\n",
    "    'REF_COL'  : 'is_fire'\n",
    "}\n",
    "\n",
    "TRAIN_DIM = 80\n",
    "\n",
    "OUT_FLD = r'F:\\geotmlnh\\text_cls'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Sanitize data to use in classification\n",
    "\"\"\"\n",
    "\n",
    "Q1 = (\n",
    "    \"(SELECT *, to_tsvector('portuguese', regexp_replace(\"\n",
    "        \"regexp_replace(lower(unaccent(txtcls)), 'http://[^:\\s]+(\\S+)', \"\n",
    "        \"' ', 'g'), '[^\\w]+', ' ', 'g')) \"\n",
    "    \"AS txtsan FROM (\"\n",
    "        \"SELECT {t}.fid, {t}.{t_id}, {txtcol} AS txtcls, \"\n",
    "        \"{dt}.{timecol} AS datahora, {t}.{refcol} \"   \n",
    "        \"FROM {t} INNER JOIN {dt} ON \"\n",
    "        \"{t}.{t_id} = {dt}.{dt_id}\"\n",
    "    \") AS foo) AS stop_table\"\n",
    ").format(\n",
    "    txtcol=TBL_SCHEMA['TXT_COL'], t=TBL_SCHEMA['SAMPLE_T'],\n",
    "    dt=TBL_SCHEMA['DATA_T'], t_id=TBL_SCHEMA['SAMPLE_FK'],\n",
    "    dt_id=TBL_SCHEMA['DATA_ID'], timecol=TBL_SCHEMA['TIME_COL'],\n",
    "    refcol=TBL_SCHEMA['REF_COL']\n",
    ")\n",
    "\n",
    "cols = ['fid', TBL_SCHEMA['TIME_COL'], TBL_SCHEMA['SAMPLE_FK'], TBL_SCHEMA['REF_COL']]\n",
    "Q2 = (\n",
    "    \"SELECT {selCols}, ARRAY_TO_STRING(array_agg(\"\n",
    "        \"word ORDER BY word_index), ' ', '*') AS txtsan, \"\n",
    "    \"REPLACE(CAST(TRIM(\"\n",
    "        \"stop_table.txtcls) AS text), '''', '') AS no_duplicated \"\n",
    "    \"FROM (\"\n",
    "        \"SELECT fid, word, CAST(UNNEST(word_index) AS integer) \"\n",
    "        \"AS word_index FROM (\"\n",
    "            \"SELECT fid, SPLIT_PART(tst, ';', 1) AS word, \"\n",
    "            \"STRING_TO_ARRAY(SPLIT_PART(tst, ';', 2), ',') AS word_index FROM (\"\n",
    "                \"SELECT fid, REPLACE(REPLACE(REPLACE(REPLACE(REPLACE(\"\n",
    "                    \"CAST(UNNEST(txtsan) AS text), \"\n",
    "                        \"',{{', ',\\\"{{'), ',\\\"{{', ';'), '}}\\\"', ''), \"\n",
    "                        \"'(', ''), '}}', '') AS tst \"\n",
    "                \"FROM {tbl}\"\n",
    "            \") AS foo\"\n",
    "        \") AS foo2\"\n",
    "    \") AS foo3 INNER JOIN {tbl} ON foo3.fid = stop_table.fid \"\n",
    "    \"GROUP BY {selCols}, stop_table.txtcls\"\n",
    ").format(\n",
    "    tbl=Q1, selCols=\", \".join([\"stop_table.{}\".format(i) for i in cols])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_ref = Q_to_df(conDB, Q2)\n",
    "\n",
    "ref_Count = df_to_freqdf(dt_ref, TBL_SCHEMA['REF_COL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN_DIM == 100:\n",
    "    dt_train = dt_ref\n",
    "    dt_cls   = dt_ref.copy()\n",
    "\n",
    "else:\n",
    "    ref_Count['n_train'] = (ref_Count['count'] * TRAIN_DIM) / 100\n",
    "    ref_Count = ref_Count.round({'n_train' : 0})\n",
    "    \n",
    "    dt_ref['RN'] = dt_ref.sort_values(\n",
    "        [TBL_SCHEMA['REF_COL']], ascending=[True]\n",
    "    ).groupby([TBL_SCHEMA['REF_COL']]).cumcount() + 1\n",
    "    \n",
    "    for idx, row in ref_Count.iterrows():\n",
    "        if idx == 0:\n",
    "            dt_ref['is_train'] = numpy.where(\n",
    "                (dt_ref['is_fire'] == row.is_fire) & (dt_ref.RN <= row.n_train),\n",
    "                1, 0\n",
    "            )\n",
    "        else:\n",
    "            dt_ref['is_train'] = numpy.where(\n",
    "                (dt_ref['is_fire'] == row.is_fire) & (dt_ref.RN <= row.n_train),\n",
    "                1, dt_ref.is_train\n",
    "            )\n",
    "    \n",
    "    dt_cls   = dt_ref[dt_ref.is_train==0]\n",
    "    dt_train = dt_ref[dt_ref.is_train==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdls = {\n",
    "    'NB' : 'NaiveBayes', 'SVM' :'LinearSupportVectorMachine',\n",
    "    'RF' : 'RandomForest', 'LOGREG':'LogisticRegression'}\n",
    "\n",
    "corr_words = correlated_words(\n",
    "    dt_train, TBL_SCHEMA['REF_COL'], 'txtsan',\n",
    "    os.path.join(OUT_FLD, 'corr_words_{}.xlsx'.format(str(TRAIN_DIM))),\n",
    "    lang='english'\n",
    ")\n",
    "\n",
    "for m in mdls:\n",
    "    tbl_cls = text_prediction(\n",
    "        dt_train, dt_cls, TBL_SCHEMA['REF_COL'], 'txtsan', 'txtsan',\n",
    "        os.path.join(OUT_FLD, 'res_{}_{}.xlsx'.format(m, str(TRAIN_DIM))),\n",
    "        lang='english', method=mdls[m]\n",
    "    )\n",
    "    \n",
    "    mtx = binary_eval(\n",
    "        tbl_cls, TBL_SCHEMA['SAMPLE_FK'], TBL_SCHEMA['REF_COL'],\n",
    "        tbl_cls, TBL_SCHEMA['SAMPLE_FK'],\n",
    "        os.path.join(OUT_FLD, 'mtx_{}_{}.xlsx'.format(m, str(TRAIN_DIM))),\n",
    "        tstCol = 'classification'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gasp3.adv.txtcls.cls import get_rows_related_with_event\n",
    "from gasp3.to import db_to_tbl\n",
    "\n",
    "QT = (\n",
    "    \"(SELECT {t}.fid, {t}.{t_id}, {txtcol} AS txtcls, \"\n",
    "    \"{dt}.{timecol} AS datahora, {t}.{refcol} \"   \n",
    "    \"FROM {t} INNER JOIN {dt} ON \"\n",
    "    \"{t}.{t_id} = {dt}.{dt_id}) AS foo\"\n",
    ").format(\n",
    "    txtcol=TBL_SCHEMA['TXT_COL'], t=TBL_SCHEMA['SAMPLE_T'],\n",
    "    dt=TBL_SCHEMA['DATA_T'], t_id=TBL_SCHEMA['SAMPLE_FK'],\n",
    "    dt_id=TBL_SCHEMA['DATA_ID'], timecol=TBL_SCHEMA['TIME_COL'],\n",
    "    refcol=TBL_SCHEMA['REF_COL']\n",
    ")\n",
    "\n",
    "tbl_ref = db_to_tbl(\n",
    "    conDB, \"SELECT * FROM {}\".format(QT),\n",
    "    os.path.join(OUT_FLD, 'tbl_ref.xlsx')\n",
    ")\n",
    "\n",
    "tbl_res = get_rows_related_with_event(conDB, {\n",
    "    \"TNAME\" : QT,\n",
    "    \"TEXTCOL\" : \"txtcls\",\n",
    "    \"TIMECOL\" : \"datahora\",\n",
    "    \"SELCOL\"  : ['fid', TBL_SCHEMA['SAMPLE_FK'], \"datahora\", TBL_SCHEMA['REF_COL']]\n",
    "}, ['fog', 'incendi'], os.path.join(OUT_FLD, 'res_q.xlsx'))\n",
    "\n",
    "mtx_q = binary_eval(\n",
    "    tbl_ref, TBL_SCHEMA['SAMPLE_FK'], TBL_SCHEMA['REF_COL'],\n",
    "    tbl_res, TBL_SCHEMA['SAMPLE_FK'],\n",
    "    os.path.join(OUT_FLD, 'mtx_q.xlsx'),\n",
    "    tstCol = None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
